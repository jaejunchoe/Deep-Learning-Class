{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1FovhIliakSRmR0Cjfeexm8c86l9SIyiT","timestamp":1713202581361}],"authorship_tag":"ABX9TyNYZwvc6oAeha+jxgS5W8yl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":963},"id":"RQRwC1GzwNPC","executionInfo":{"status":"error","timestamp":1713225070389,"user_tz":-540,"elapsed":20657555,"user":{"displayName":"최재준","userId":"15020848563771571160"}},"outputId":"dd69520b-9af4-494a-aabd-6507190b922a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Activation: ReLU(), LR: 0.001, Optimizer: SGD, Accuracy: 0.8271\n","Activation: ReLU(), LR: 0.001, Optimizer: Momentum, Accuracy: 0.8815\n","Activation: ReLU(), LR: 0.001, Optimizer: Adagrad, Accuracy: 0.8525\n","Activation: ReLU(), LR: 0.001, Optimizer: RMSprop, Accuracy: 0.8855\n","Activation: ReLU(), LR: 0.001, Optimizer: Adam, Accuracy: 0.8845\n","Activation: ReLU(), LR: 0.01, Optimizer: SGD, Accuracy: 0.8795\n","Activation: ReLU(), LR: 0.01, Optimizer: Momentum, Accuracy: 0.8952\n","Activation: ReLU(), LR: 0.01, Optimizer: Adagrad, Accuracy: 0.8946\n","Activation: ReLU(), LR: 0.01, Optimizer: RMSprop, Accuracy: 0.7682\n","Activation: ReLU(), LR: 0.01, Optimizer: Adam, Accuracy: 0.8544\n","Activation: ReLU(), LR: 0.1, Optimizer: SGD, Accuracy: 0.8857\n","Activation: ReLU(), LR: 0.1, Optimizer: Momentum, Accuracy: 0.3397\n","Activation: ReLU(), LR: 0.1, Optimizer: Adagrad, Accuracy: 0.8753\n","Activation: ReLU(), LR: 0.1, Optimizer: RMSprop, Accuracy: 0.1\n","Activation: ReLU(), LR: 0.1, Optimizer: Adam, Accuracy: 0.1\n","Activation: Tanh(), LR: 0.001, Optimizer: SGD, Accuracy: 0.8229\n","Activation: Tanh(), LR: 0.001, Optimizer: Momentum, Accuracy: 0.8764\n","Activation: Tanh(), LR: 0.001, Optimizer: Adagrad, Accuracy: 0.8605\n","Activation: Tanh(), LR: 0.001, Optimizer: RMSprop, Accuracy: 0.8723\n","Activation: Tanh(), LR: 0.001, Optimizer: Adam, Accuracy: 0.8804\n","Activation: Tanh(), LR: 0.01, Optimizer: SGD, Accuracy: 0.8697\n","Activation: Tanh(), LR: 0.01, Optimizer: Momentum, Accuracy: 0.8889\n","Activation: Tanh(), LR: 0.01, Optimizer: Adagrad, Accuracy: 0.8921\n","Activation: Tanh(), LR: 0.01, Optimizer: RMSprop, Accuracy: 0.722\n","Activation: Tanh(), LR: 0.01, Optimizer: Adam, Accuracy: 0.7545\n","Activation: Tanh(), LR: 0.1, Optimizer: SGD, Accuracy: 0.8896\n","Activation: Tanh(), LR: 0.1, Optimizer: Momentum, Accuracy: 0.7922\n","Activation: Tanh(), LR: 0.1, Optimizer: Adagrad, Accuracy: 0.8642\n","Activation: Tanh(), LR: 0.1, Optimizer: RMSprop, Accuracy: 0.3515\n","Activation: Tanh(), LR: 0.1, Optimizer: Adam, Accuracy: 0.1958\n","Activation: Softmax(dim=1), LR: 0.001, Optimizer: SGD, Accuracy: 0.1\n","Activation: Softmax(dim=1), LR: 0.001, Optimizer: Momentum, Accuracy: 0.1\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-29c523391e7c>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3101\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3016\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MAPMODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3018\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3019\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2930\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2931\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2932\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.optim import SGD, Adam, RMSprop, Adagrad\n","\n","# 데이터셋 설정\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","\n","train_set = torchvision.datasets.FashionMNIST(root='./data',\n","                                              train=True,\n","                                              download=True,\n","                                              transform=transform)\n","test_set = torchvision.datasets.FashionMNIST(root='./data',\n","                                             train=False,\n","                                             download=True,\n","                                             transform=transform)\n","\n","train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n","\n","# 모델 정의\n","class MLP(nn.Module):\n","    def __init__(self, activation_func=nn.ReLU()):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.layer1 = nn.Linear(28*28, 256)\n","        self.activation = activation_func\n","        self.layer2 = nn.Linear(256, 128)\n","        self.output = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.activation(self.layer1(x))\n","        x = self.activation(self.layer2(x))\n","        x = self.output(x)\n","        return x\n","\n","# 모델 인스턴스화 및 하이퍼파라미터 설정\n","activation_functions = [nn.ReLU(), nn.Tanh(), nn.Softmax(dim=1)]\n","learning_rates = [0.001, 0.01, 0.1]\n","epochs = 30\n","\n","# 최적화 함수 설정\n","optimizer_functions = {\n","    'SGD': lambda params, lr: SGD(params, lr=lr),\n","    'Momentum': lambda params, lr: SGD(params, lr=lr, momentum=0.9),\n","    'Adagrad': lambda params, lr: Adagrad(params, lr=lr),\n","    'RMSprop': lambda params, lr: RMSprop(params, lr=lr),\n","    'Adam': lambda params, lr: Adam(params, lr=lr)\n","}\n","\n","\n","# 결과 저장을 위한 딕셔너리\n","results = {}\n","\n","\n","\n","for activation_func in activation_functions:\n","    for lr in learning_rates:\n","        for opt_name, opt_func in optimizer_functions.items():\n","            # 모델 초기화\n","            model = MLP(activation_func=activation_func)\n","            optimizer = opt_func(model.parameters(), lr=lr)\n","            # 손실 함수\n","            loss_fn = nn.CrossEntropyLoss()\n","\n","            # 훈련\n","            for epoch in range(epochs):\n","                model.train()\n","                for batch, (X, y) in enumerate(train_loader):\n","                    pred = model(X)\n","                    loss = loss_fn(pred, y)\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # 평가\n","            model.eval()\n","            correct = 0\n","            total = 0\n","            with torch.no_grad():\n","                for X, y in test_loader:\n","                    pred = model(X)\n","                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","                    total += y.size(0)\n","\n","            accuracy = correct / total\n","            print(f\"Activation: {activation_func}, LR: {lr}, Optimizer: {opt_name}, Accuracy: {accuracy}\")\n","            results[(str(activation_func), lr, opt_name)] = accuracy\n","\n","################# 너무 오래걸려서 softmax은 코드를 따로 생성해서 돌리도록 하겠습니다.\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"zje5QeuSDs2N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zdKdAMM4Ds5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.optim import SGD, Adam, RMSprop, Adagrad\n","\n","# 데이터셋 설정\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","\n","train_set = torchvision.datasets.FashionMNIST(root='./data',\n","                                              train=True,\n","                                              download=True,\n","                                              transform=transform)\n","test_set = torchvision.datasets.FashionMNIST(root='./data',\n","                                             train=False,\n","                                             download=True,\n","                                             transform=transform)\n","\n","train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n","\n","# 모델 정의\n","class MLP(nn.Module):\n","    def __init__(self, activation_func=nn.ReLU()):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.layer1 = nn.Linear(28*28, 256)\n","        self.activation = activation_func\n","        self.layer2 = nn.Linear(256, 128)\n","        self.output = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.activation(self.layer1(x))\n","        x = self.activation(self.layer2(x))\n","        x = self.output(x)\n","        return x\n","\n","# 모델 인스턴스화 및 하이퍼파라미터 설정\n","activation_functions = [nn.ReLU(), nn.Tanh(), nn.Softmax(dim=1)]\n","learning_rates = [0.001, 0.01, 0.1]\n","epochs = 30\n","\n","# 최적화 함수 설정\n","optimizer_functions = {\n","    'SGD': lambda params, lr: SGD(params, lr=lr),\n","    'Momentum': lambda params, lr: SGD(params, lr=lr, momentum=0.9),\n","    'Adagrad': lambda params, lr: Adagrad(params, lr=lr),\n","    'RMSprop': lambda params, lr: RMSprop(params, lr=lr),\n","    'Adam': lambda params, lr: Adam(params, lr=lr)\n","}\n","\n","\n","# 결과 저장을 위한 딕셔너리\n","results = {}\n","\n","\n","\n","for activation_func in activation_functions:\n","    for lr in learning_rates:\n","        for opt_name, opt_func in optimizer_functions.items():\n","            # 모델 초기화\n","            model = MLP(activation_func=activation_func)\n","            optimizer = opt_func(model.parameters(), lr=lr)\n","            # 손실 함수\n","            loss_fn = nn.CrossEntropyLoss()\n","\n","            # 훈련\n","            for epoch in range(epochs):\n","                model.train()\n","                for batch, (X, y) in enumerate(train_loader):\n","                    pred = model(X)\n","                    loss = loss_fn(pred, y)\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # 평가\n","            model.eval()\n","            correct = 0\n","            total = 0\n","            with torch.no_grad():\n","                for X, y in test_loader:\n","                    pred = model(X)\n","                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","                    total += y.size(0)\n","\n","            accuracy = correct / total\n","            print(f\"Activation: {activation_func}, LR: {lr}, Optimizer: {opt_name}, Accuracy: {accuracy}\")\n","            results[(str(activation_func), lr, opt_name)] = accuracy\n","\n","\n","\n","\n"],"metadata":{"id":"yJ5rkbwZDs6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.optim import SGD, Adam, RMSprop, Adagrad\n","\n","# 데이터셋 설정\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","\n","train_set = torchvision.datasets.FashionMNIST(root='./data',\n","                                              train=True,\n","                                              download=True,\n","                                              transform=transform)\n","test_set = torchvision.datasets.FashionMNIST(root='./data',\n","                                             train=False,\n","                                             download=True,\n","                                             transform=transform)\n","\n","train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n","\n","# 모델 정의\n","class MLP(nn.Module):\n","    def __init__(self, activation_func=nn.ReLU()):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.layer1 = nn.Linear(28*28, 256)\n","        self.activation = activation_func\n","        self.layer2 = nn.Linear(256, 128)\n","        self.output = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.activation(self.layer1(x))\n","        x = self.activation(self.layer2(x))\n","        x = self.output(x)\n","        return x\n","\n","# 모델 인스턴스화 및 하이퍼파라미터 설정\n","activation_functions = [nn.ReLU(), nn.Tanh(), nn.Softmax(dim=1)]\n","learning_rates = [0.001, 0.01, 0.1]\n","epochs = 30\n","\n","# 최적화 함수 설정\n","optimizer_functions = {\n","    'SGD': lambda params, lr: SGD(params, lr=lr),\n","    'Momentum': lambda params, lr: SGD(params, lr=lr, momentum=0.9),\n","    'Adagrad': lambda params, lr: Adagrad(params, lr=lr),\n","    'RMSprop': lambda params, lr: RMSprop(params, lr=lr),\n","    'Adam': lambda params, lr: Adam(params, lr=lr)\n","}\n","\n","\n","# 결과 저장을 위한 딕셔너리\n","results = {}\n","\n","\n","\n","for activation_func in activation_functions:\n","    for lr in learning_rates:\n","        for opt_name, opt_func in optimizer_functions.items():\n","            # 모델 초기화\n","            model = MLP(activation_func=activation_func)\n","            optimizer = opt_func(model.parameters(), lr=lr)\n","            # 손실 함수\n","            loss_fn = nn.CrossEntropyLoss()\n","\n","            # 훈련\n","            for epoch in range(epochs):\n","                model.train()\n","                for batch, (X, y) in enumerate(train_loader):\n","                    pred = model(X)\n","                    loss = loss_fn(pred, y)\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # 평가\n","            model.eval()\n","            correct = 0\n","            total = 0\n","            with torch.no_grad():\n","                for X, y in test_loader:\n","                    pred = model(X)\n","                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","                    total += y.size(0)\n","\n","            accuracy = correct / total\n","            print(f\"Activation: {activation_func}, LR: {lr}, Optimizer: {opt_name}, Accuracy: {accuracy}\")\n","            results[(str(activation_func), lr, opt_name)] = accuracy\n","\n","\n","\n","\n"],"metadata":{"id":"lrYKX3miDs9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.optim import SGD, Adam, RMSprop, Adagrad\n","\n","# 데이터셋 설정\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","\n","train_set = torchvision.datasets.FashionMNIST(root='./data',\n","                                              train=True,\n","                                              download=True,\n","                                              transform=transform)\n","test_set = torchvision.datasets.FashionMNIST(root='./data',\n","                                             train=False,\n","                                             download=True,\n","                                             transform=transform)\n","\n","train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n","\n","# 모델 정의\n","class MLP(nn.Module):\n","    def __init__(self, activation_func=nn.ReLU()):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.layer1 = nn.Linear(28*28, 256)\n","        self.activation = activation_func\n","        self.layer2 = nn.Linear(256, 128)\n","        self.output = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.activation(self.layer1(x))\n","        x = self.activation(self.layer2(x))\n","        x = self.output(x)\n","        return x\n","\n","# 모델 인스턴스화 및 하이퍼파라미터 설정\n","activation_functions = [nn.Softmax(dim=1)]\n","learning_rates = [0.001, 0.01, 0.1]\n","epochs = 30\n","\n","# 최적화 함수 설정\n","optimizer_functions = {\n","    'SGD': lambda params, lr: SGD(params, lr=lr),\n","    'Momentum': lambda params, lr: SGD(params, lr=lr, momentum=0.9),\n","    'Adagrad': lambda params, lr: Adagrad(params, lr=lr),\n","    'RMSprop': lambda params, lr: RMSprop(params, lr=lr),\n","    'Adam': lambda params, lr: Adam(params, lr=lr)\n","}\n","\n","\n","# 결과 저장을 위한 딕셔너리\n","results = {}\n","\n","\n","\n","for activation_func in activation_functions:\n","    for lr in learning_rates:\n","        for opt_name, opt_func in optimizer_functions.items():\n","            # 모델 초기화\n","            model = MLP(activation_func=activation_func)\n","            optimizer = opt_func(model.parameters(), lr=lr)\n","            # 손실 함수\n","            loss_fn = nn.CrossEntropyLoss()\n","\n","            # 훈련\n","            for epoch in range(epochs):\n","                model.train()\n","                for batch, (X, y) in enumerate(train_loader):\n","                    pred = model(X)\n","                    loss = loss_fn(pred, y)\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # 평가\n","            model.eval()\n","            correct = 0\n","            total = 0\n","            with torch.no_grad():\n","                for X, y in test_loader:\n","                    pred = model(X)\n","                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","                    total += y.size(0)\n","\n","            accuracy = correct / total\n","            print(f\"Activation: {activation_func}, LR: {lr}, Optimizer: {opt_name}, Accuracy: {accuracy}\")\n","            results[(str(activation_func), lr, opt_name)] = accuracy\n","\n"],"metadata":{"id":"evD09l5lLKoz"},"execution_count":null,"outputs":[]}]}